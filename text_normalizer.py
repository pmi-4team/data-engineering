import re
import redis
from kiwipiepy import Kiwi


class TextNormalizer:
    def __init__(self, redis_host="localhost", redis_port=6379):
        print("âœ… TextNormalizer: Redis ì—°ê²° ì‹œë„ ì¤‘...")
        self.redis_client = redis.StrictRedis(host=redis_host, port=redis_port, decode_responses=True)
        print("âœ… TextNormalizer: Redis ì—°ê²° ì„±ê³µ")

        print("ğŸ”§ TextNormalizer: Kiwipiepy ì´ˆê¸°í™” ì¤‘...")
        self.kiwi = Kiwi()
        print("âœ… TextNormalizer: Kiwipiepy ì´ˆê¸°í™” ì™„ë£Œ")

        self.typo_rules = self.load_rules_from_redis("TYPO")
        self.synonym_rules = self.load_rules_from_redis("SYNONYM")
        print("âœ… TextNormalizer: ê·œì¹™ ë¡œë“œ ì™„ë£Œ\n")
        
        # âœ… ë³µí•©ì–´ ì ‘ë¯¸ì‚¬ ëª©ë¡
        self.compound_suffixes = ['ë„', 'ë¥ ', 'ìœ¨', 'ì ', 'ì„±', 'ê°', 'ë ¥', 'ëŠ¥']

    def load_rules_from_redis(self, rule_type):
        key_map = {
            "TYPO": ["typo_rules", "dictionary_rules:TYPO"],
            "SYNONYM": ["synonym_rules", "dictionary_rules:SYNONYM"],
        }

        redis_key = None
        for k in key_map.get(rule_type, []):
            if self.redis_client.exists(k):
                redis_key = k
                print(f"  ğŸ” [{rule_type}] Redis í‚¤ ë°œê²¬: '{k}'")
                break

        if not redis_key:
            redis_key = f"{rule_type.lower()}_rules"

        keys = self.redis_client.hkeys(redis_key)
        rules = []
        for k in keys:
            v = self.redis_client.hget(redis_key, k)
            if k and v:
                k = re.sub(r"\s+", " ", k.strip())
                v = re.sub(r"\s+", " ", v.strip())
                rules.append((k, v))

        print(f"  âœ… [{rule_type}] ê·œì¹™ ë¡œë“œ ì™„ë£Œ: {len(rules)}ê°œ from '{redis_key}'")
        return rules

    def normalize(self, text: str, verbose=False):
        print(f"\n[ì •ì œ ì‹œì‘] ì›ë³¸: {text}")
        print("=" * 60)

        text = self.preprocess_text(text)
        print(f"0ï¸âƒ£ ì „ì²˜ë¦¬: {text}")

        text, typo_applied = self.apply_replacements(text, self.typo_rules, "Typo")
        if typo_applied:
            print(f"1ï¸âƒ£ Typo êµì • í›„: {text}")
        else:
            print(f"1ï¸âƒ£ Typo êµì •: (ë³€í™” ì—†ìŒ)")

        text, syn_applied = self.apply_replacements(text, self.synonym_rules, "Synonym")
        if syn_applied:
            print(f"2ï¸âƒ£ Synonym í‘œì¤€í™” í›„: {text}")
        else:
            print(f"2ï¸âƒ£ Synonym í‘œì¤€í™”: (ë³€í™” ì—†ìŒ)")

        tokens = [(t.form, t.tag) for t in self.kiwi.tokenize(text)]
        print(f"3ï¸âƒ£ í† í°í™” ê²°ê³¼: {tokens}")

        text = self.postprocess_text(text)
        print(f"âœ… ìµœì¢… ê²°ê³¼: {text}")
        print("=" * 60)
        
        return text

    def preprocess_text(self, text: str):
        text = text.strip()
        text = re.sub(r"\s+", " ", text)
        text = re.sub(r"[''""]", "'", text)
        text = re.sub(r"['\"]+", "", text)
        text = re.sub(r"[^ê°€-í£a-zA-Z0-9\s\.\!\?\~\-]", " ", text)
        text = re.sub(r"([.!?~])\1+", r"\1", text)
        text = re.sub(r"([.!?]){2,}$", r"\1", text)
        text = re.sub(r"\s+", " ", text).strip()
        return text

    def apply_replacements(self, text: str, rules, stage_name: str):
        """
        êµì²´ ë¡œì§ - ë³µí•©ì–´ ë³´í˜¸ ì¶”ê°€!
        """
        applied = []
        replaced_spans = []
        
        if not rules:
            return text, applied

        sorted_rules = sorted(rules, key=lambda x: len(x[0]), reverse=True)
        
        print(f"\n  ğŸ” [{stage_name}] ê·œì¹™ ì ìš© ì‹œì‘ (ì´ {len(sorted_rules)}ê°œ ê·œì¹™)")

        for term_from, term_to in sorted_rules:
            if not term_from or not term_to:
                continue
            if len(term_from) < 2:
                continue

            # ê³µë°± ìœ ì—° ë§¤ì¹­
            escaped = re.escape(term_from).replace(r"\ ", r"\s+")

            # íŒ¨í„´ ìƒì„±
            if stage_name.lower() == "typo":
                pattern = re.compile(rf"(?<![ê°€-í£A-Za-z0-9]){escaped}(?![ê°€-í£A-Za-z0-9])")
            else:
                pattern = re.compile(rf"(?<![ê°€-í£A-Za-z0-9]){escaped}(?![A-Za-z0-9])")
            
            matches = list(pattern.finditer(text))
            
            # ë””ë²„ê¹…
            if len(applied) < 5 and matches:
                print(f"    âœ“ ë§¤ì¹­: '{term_from}' â†’ '{term_to}' ({len(matches)}ê°œ ë§¤ì¹­)")

            for m in matches:
                start, end = m.span()

                # ì¡°ê±´ 1: ì´ë¯¸ êµì²´ëœ ì˜ì—­ skip
                if any(s <= start < e or s < end <= e for s, e in replaced_spans):
                    if len(applied) < 5:
                        print(f"       âŠ˜ Skip: ì´ë¯¸ êµì²´ëœ ì˜ì—­")
                    continue

                # ì¡°ê±´ 2: '~' ì£¼ë³€ skip
                if '~' in text[max(0, start - 3): min(len(text), end + 3)]:
                    if len(applied) < 5:
                        print(f"       âŠ˜ Skip: '~' ì£¼ë³€")
                    continue

                # âœ… ì¡°ê±´ 3: ì´ë¯¸ ì™„ì„±ëœ í˜•íƒœ skip
                matched_text = text[start:end]
                after_match = text[start:start+len(term_to)]
                
                if after_match == term_to:
                    if len(applied) < 5:
                        print(f"       âŠ˜ Skip: ì´ë¯¸ ì™„ì„±ëœ í˜•íƒœ ('{term_to}'ê°€ ì´ë¯¸ ì¡´ì¬)")
                    continue

                # âœ… ì¡°ê±´ 4: ë³µí•©ì–´ ë³´í˜¸ (Synonymë§Œ)
                if stage_name.lower() == "synonym":
                    # ë§¤ì¹­ ë’¤ì— ë³µí•©ì–´ ì ‘ë¯¸ì‚¬ê°€ ë°”ë¡œ ì˜¤ë©´ skip
                    next_char_pos = end
                    if next_char_pos < len(text):
                        next_char = text[next_char_pos]
                        if next_char in self.compound_suffixes:
                            if len(applied) < 5:
                                print(f"       âŠ˜ Skip: ë³µí•©ì–´ ('{matched_text}{next_char}')")
                            continue

                # ì‹¤ì œ êµì²´
                text = text[:start] + term_to + text[end:]
                replaced_spans.append((start, start + len(term_to)))
                applied.append((term_from, term_to))
                
                print(f"    âœ… ì ìš©: '{matched_text}' â†’ '{term_to}'")
                break

        if applied:
            print(f"  ğŸ“Š [{stage_name}] ì ìš© ì™„ë£Œ: {len(applied)}ê°œ ê·œì¹™ ì ìš©ë¨")
        else:
            print(f"  â„¹ï¸  [{stage_name}] ì ìš©ëœ ê·œì¹™ ì—†ìŒ")
        
        return text, applied

    def postprocess_text(self, text: str):
        # 1. ê°™ì€ ë‹¨ì–´ ë°˜ë³µ ì œê±°
        text = re.sub(r"\b(\w+)( \1\b)+", r"\1", text)
        
        # 2. í•œê¸€ ë‹¨ì–´ ë°˜ë³µ ì œê±°
        text = re.sub(r"([ê°€-í£]+)\s+\1", r"\1", text)
        
        # 3. ì–´ë¯¸ ë°˜ë³µ ì œê±°
        text = re.sub(r"(ì´ë‹¤|ì…ë‹ˆë‹¤|ì—ˆë‹¤|ì•˜ë‹¤|ìˆë‹¤|ì—†ë‹¤|í•˜ë‹¤|í•œë‹¤)(\1)+", r"\1", text)
        
        # 4. ê³µë°± ì •ë¦¬
        text = re.sub(r"\s+", " ", text).strip()
        
        return text
