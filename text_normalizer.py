import re
import redis


class TextNormalizer:
    def __init__(self, redis_host="localhost", redis_port=6379):
        print("âœ… TextNormalizer: Redis ì—°ê²° ì‹œë„ ì¤‘...")
        self.redis_client = redis.StrictRedis(host=redis_host, port=redis_port, decode_responses=True)
        print("âœ… TextNormalizer: Redis ì—°ê²° ì„±ê³µ")

        # Redisì—ì„œ ê·œì¹™ ë¡œë“œ
        self.typo_rules = self.load_rules_from_redis("TYPO")
        self.synonym_rules = self.load_rules_from_redis("SYNONYM")
        print("âœ… TextNormalizer: ê·œì¹™ ë¡œë“œ ì™„ë£Œ\n")

        # âœ… ë³µí•©ì–´ ì ‘ë¯¸ì‚¬ ëª©ë¡
        self.compound_suffixes = ['ë„', 'ë¥ ', 'ìœ¨', 'ì ', 'ì„±', 'ê°', 'ë ¥', 'ëŠ¥']

        # âœ… ë™ì‚¬/í˜•ìš©ì‚¬ ì–´ë¯¸ í™•ì¥ ì„¸íŠ¸
        self.verb_suffixes = ['í•˜', 'í•´', 'í–ˆ', 'í•˜ê³ ', 'í•˜ëŠ”', 'í–ˆë‹¤', 'í•˜ë©°', 'í•˜ê²Œ', 'í•˜ì—¬']

    # -----------------------------------------------------
    def load_rules_from_redis(self, rule_type):
        """Redisì—ì„œ ê·œì¹™ ë¡œë“œ"""
        key_map = {
            "TYPO": ["typo_rules", "dictionary_rules:TYPO"],
            "SYNONYM": ["synonym_rules", "dictionary_rules:SYNONYM"],
        }

        redis_key = None
        for k in key_map.get(rule_type, []):
            if self.redis_client.exists(k):
                redis_key = k
                print(f"  ğŸ” [{rule_type}] Redis í‚¤ ë°œê²¬: '{k}'")
                break

        if not redis_key:
            redis_key = f"{rule_type.lower()}_rules"

        keys = self.redis_client.hkeys(redis_key)
        rules = []
        for k in keys:
            v = self.redis_client.hget(redis_key, k)
            if k and v:
                k = re.sub(r"\s+", " ", k.strip())
                v = re.sub(r"\s+", " ", v.strip())
                rules.append((k, v))

        print(f"  âœ… [{rule_type}] ê·œì¹™ ë¡œë“œ ì™„ë£Œ: {len(rules)}ê°œ from '{redis_key}'")
        return rules

    # -----------------------------------------------------
    def normalize(self, text: str, verbose=False):
        """ë¬¸ìì—´ ê¸°ë°˜ ì •ì œ ì „ì²´ íŒŒì´í”„ë¼ì¸"""
        print(f"\n[ì •ì œ ì‹œì‘] ì›ë³¸: {text}")
        print("=" * 60)

        text = self.preprocess_text(text)
        print(f"0ï¸âƒ£ ì „ì²˜ë¦¬: {text}")

        # ì˜¤íƒˆì êµì •
        text, typo_applied = self.apply_replacements(text, self.typo_rules, "Typo")
        if typo_applied:
            print(f"1ï¸âƒ£ Typo êµì • í›„: {text}")
        else:
            print(f"1ï¸âƒ£ Typo êµì •: (ë³€í™” ì—†ìŒ)")

        # ë™ì˜ì–´ í‘œì¤€í™”
        text, syn_applied = self.apply_replacements(text, self.synonym_rules, "Synonym")
        if syn_applied:
            print(f"2ï¸âƒ£ Synonym í‘œì¤€í™” í›„: {text}")
        else:
            print(f"2ï¸âƒ£ Synonym í‘œì¤€í™”: (ë³€í™” ì—†ìŒ)")

        # í›„ì²˜ë¦¬
        text = self.postprocess_text(text)
        print(f"âœ… ìµœì¢… ê²°ê³¼: {text}")
        print("=" * 60)

        return text

    # -----------------------------------------------------
    def preprocess_text(self, text: str):
        """ê¸°ë³¸ ì „ì²˜ë¦¬: ê³µë°±/ê¸°í˜¸ ì •ë¦¬"""
        text = text.strip()
        text = re.sub(r"\s+", " ", text)
        text = re.sub(r"[''""]", "'", text)
        text = re.sub(r"['\"]+", "", text)
        text = re.sub(r"[^ê°€-í£a-zA-Z0-9\s\.\!\?\~\-\(\)]", " ", text)  # âœ… ê´„í˜¸ í—ˆìš©
        text = re.sub(r"([.!?~])\1+", r"\1", text)
        text = re.sub(r"([.!?]){2,}$", r"\1", text)
        text = re.sub(r"\s+", " ", text).strip()
        return text

    # -----------------------------------------------------
    def apply_replacements(self, text: str, rules, stage_name: str):
        """ë¬¸ìì—´ ê¸°ë°˜ êµì²´ ë¡œì§ (ë¶€ë¶„ ê²¹ì¹¨ í—ˆìš© ë²„ì „)"""
        applied = []
        replaced_spans = []

        if not rules:
            return text, applied

        # ê¸´ ë‹¨ì–´ ìš°ì„  êµì²´
        sorted_rules = sorted(rules, key=lambda x: len(x[0]), reverse=True)
        print(f"\n  ğŸ” [{stage_name}] ê·œì¹™ ì ìš© ì‹œì‘ (ì´ {len(sorted_rules)}ê°œ ê·œì¹™)")

        for term_from, term_to in sorted_rules:
            if not term_from or not term_to or len(term_from) < 2:
                continue

            escaped = re.escape(term_from).replace(r"\ ", r"\s+")

            # ì¡°ì‚¬ ë° ì–´ë¯¸ í—ˆìš©
            if stage_name.lower() == "typo":
                pattern = re.compile(
                    rf"(?<![ê°€-í£A-Za-z0-9]){escaped}"
                    rf"(?=[^ê°€-í£A-Za-z0-9]|[ì—ì—ì„œë¡œë„ë§Œì€ëŠ”ì´ê°€]?|"
                    rf"[ê°€-í£]*({'|'.join(self.verb_suffixes)})?|$)"
                )
            else:
                pattern = re.compile(
                    rf"(?<![ê°€-í£A-Za-z0-9]){escaped}"
                    rf"(?=[^A-Za-z0-9]|[ì—ì—ì„œë¡œë„ë§Œì€ëŠ”ì´ê°€]?|"
                    rf"[ê°€-í£]*({'|'.join(self.verb_suffixes)})?|$)"
                )

            matches = list(pattern.finditer(text))

            if len(applied) < 5 and matches:
                print(f"    âœ“ ë§¤ì¹­: '{term_from}' â†’ '{term_to}' ({len(matches)}ê°œ ë§¤ì¹­)")

            for m in matches:
                start, end = m.span()

                # âœ… ì™„ì „íˆ í¬í•¨ëœ ê²½ìš°ë§Œ skip (ë¶€ë¶„ ê²¹ì¹¨ì€ í—ˆìš©)
                if any(s <= start and end <= e for s, e in replaced_spans):
                    continue

                if '~' in text[max(0, start - 3): min(len(text), end + 3)]:
                    continue

                matched_text = text[start:end]
                after_match = text[start:start + len(term_to)]
                if after_match == term_to:
                    continue

                # ë³µí•©ì–´ ë³´í˜¸ (ì˜ˆ: "ê°ì„±ì " â†’ "ê°ì„±" ë°©ì§€)
                if stage_name.lower() == "synonym":
                    next_char_pos = end
                    if next_char_pos < len(text):
                        next_char = text[next_char_pos]
                        if next_char in self.compound_suffixes:
                            continue

                # êµì²´ ì‹¤í–‰
                text = text[:start] + term_to + text[end:]
                replaced_spans.append((start, start + len(term_to)))
                applied.append((term_from, term_to))
                break

        if applied:
            print(f"  ğŸ“Š [{stage_name}] ì ìš© ì™„ë£Œ: {len(applied)}ê°œ ê·œì¹™ ì ìš©ë¨")
        else:
            print(f"  â„¹ï¸  [{stage_name}] ì ìš©ëœ ê·œì¹™ ì—†ìŒ")

        return text, applied

    # -----------------------------------------------------
    def postprocess_text(self, text: str):
        """í›„ì²˜ë¦¬: ë°˜ë³µ ë‹¨ì–´/ê³µë°± ì •ë¦¬"""
        text = re.sub(r"\b(\w+)( \1\b)+", r"\1", text)
        text = re.sub(r"([ê°€-í£]+)\s+\1\b", r"\1", text)
        text = re.sub(r"(ì´ë‹¤|ì…ë‹ˆë‹¤|ì—ˆë‹¤|ì•˜ë‹¤|ìˆë‹¤|ì—†ë‹¤|í•˜ë‹¤|í•œë‹¤)(\1)+", r"\1", text)
        text = re.sub(r"(\S+\([^)]+\))\s+\1", r"\1", text)
        text = re.sub(r"(\S+(?:\s+\S+){0,3})\s+\1", r"\1", text)
        text = re.sub(r"(\b[ê°€-í£a-zA-Z0-9\s]+)\s+\1\b", r"\1", text)
        text = re.sub(r"\s+", " ", text).strip()
        return text
